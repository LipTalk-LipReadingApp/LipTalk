{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10dcwDVdiXezpw1hcLxCAAv1VEYHSWDrD","timestamp":1715695837199}],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**1. Importing libraries and loading data**"],"metadata":{"id":"mt0BYdBUdJiM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDwV2tJ0C_XN"},"outputs":[],"source":["#Importing librairies\n","import os\n","import cv2\n","import tensorflow as tf\n","import numpy as np\n","import math\n","from matplotlib import pyplot as plt\n","import imageio"]},{"cell_type":"code","source":["#Downloading and loading data\n","import gdown\n","url = 'https://drive.google.com/uc?id=1tMM16j54blSffGrXRXXWqIzH5SpjPT4F'\n","output = 'data.zip'\n","gdown.download(url, output, quiet=False)\n","gdown.extractall('data.zip')"],"metadata":{"id":"n5T6jgq3DlMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Setting physical devices to GPU if possible, changing to CPU otherwise\n","physical_devices = tf.config.list_physical_devices(\"GPU\")\n","try:\n","    tf.config.experimental.get_memory_growth(physical_devices[0], True)\n","except:\n","    pass"],"metadata":{"id":"NLJF9G_Bd1Ct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2. Initiating prerequisites for the data pipeline**"],"metadata":{"id":"LldkfLLEeIPO"}},{"cell_type":"code","source":["#Range of different clusters that the neural network needs to be able to predict\n","vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"],"metadata":{"id":"eYCki0CXIDGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\") #takes character and converts to number\n","num_to_char = tf.keras.layers.StringLookup(\n","    vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert = True  #takes number and converts to character\n",")"],"metadata":{"id":"nmXV0xW7Jdrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Building video_loading function\n","\n","def load_video(path:str) -> list[float]: #takes in a video and returns a list of floats\n","\n","  cap = cv2.VideoCapture(path) #initiates cv2 video instance\n","  frames = [] #list to store frames in\n","  frame_number = 0  #counter for the maximum number of frames to crop from each video\n","  for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): #iterates over every frame in the video input and keeps track of the count of frames\n","    ret, frame = cap.read()\n","    frame = tf.image.rgb_to_grayscale(frame)\n","    frames.append(frame[140:186, 110:250, :]) #cropping portion of the video that includes the mouth and appending cropped image to frames\n","    frame_number += 1\n","    if frame_number== 75:\n","      break\n","  cap.release() #releasing resources\n","\n","#rescales the data and converts the images to float32 format:\n","  mean = tf.math.reduce_mean(frames)\n","  std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n","  return tf.cast((frames - mean), tf.float32) / std"],"metadata":{"id":"JvUNsnoeGJJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Building load_alignments function\n","\n","def load_alignments(path:str) -> list[str]: #takes in an alignment and returns a list of numbers\n","  with open(path, \"r\") as f:    #opens and reads lines in alignments\n","    lines = f.readlines()\n","  tokens = []\n","  for line in lines:\n","    line = line.split()   #splits the lines\n","    if line[2] != \"sil\":\n","      tokens = [*tokens, \" \", line[2]] #appends the alignments to tokens if not silence (sil)\n","  return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding=\"UTF-8\"), (-1)))[1:] #returns alignments as numbers"],"metadata":{"id":"QxgL82vtLyBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Building data loading function that calls video and alignments laoding functions in order to load videos and alignments simultaneously\n","\n","def load_data(path: str):\n","  path = bytes.decode(path.numpy()) #converts to numpy array and string format\n","\n","  file_name = path.split(\"/\")[-1].split(\".\")[0] #splits path\n","\n","  video_path = os.path.join('data','videos',f\"{file_name}.mp4\")   #assigns path to video\n","  alignment_path = os.path.join('data','alignments',f\"{file_name}.align\")    #assigns path to alignment\n","\n","  frames = load_video(video_path) #calls load_video function\n","  alignments = load_alignments(alignment_path)  #calls load_alignments function\n","\n","  return frames, alignments\n"],"metadata":{"id":"yseSW1vBZBQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Building mappable function to use in data pipeline:\n","\n","def mappable_function(path:str) -> list[str]:\n","  result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n","  return result"],"metadata":{"id":"i0x5gQ7qdDVL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Constructing data pipeline**"],"metadata":{"id":"JRLDzUX62zRH"}},{"cell_type":"code","source":["#Data pipeline\n","data = tf.data.Dataset.list_files(\"./data/videos/*.mp4\")  #accessing dataset we have stored and selecting all videos\n","data = data.shuffle(60)  #shuffling data\n","data = data.map(mappable_function)  #calling mappable_function specified before which converts the filepath of each data point into tensors by calling load_data function on every data point (i.e. every video)\n","data = data.padded_batch(1, padded_shapes=([75, None, None, None],[40])) #normalizing everything: batches of 2 videos and corresponding alignments with 75 frames per video and 40 tokens for each alignment\n","data = data.prefetch(tf.data.AUTOTUNE)\n","#splitting data into train and test sets\n","train = data.take(45)\n","test = data.skip(45)"],"metadata":{"id":"YM98AMsV25c-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-sKHuawSMEk","executionInfo":{"status":"ok","timestamp":1739269625603,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ikbel","userId":"00064430573660104859"}},"outputId":"170eedda-c3f4-4ffd-8d1f-b1672ef58eda"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["45"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["len(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJKYjNCLjAJ6","executionInfo":{"status":"ok","timestamp":1739269627378,"user_tz":-60,"elapsed":31,"user":{"displayName":"Ikbel","userId":"00064430573660104859"}},"outputId":"18ef6ede-cd94-45c4-fd0e-07423a369328"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**4.Designing deep neural network**"],"metadata":{"id":"e0tVhvdf9lKv"}},{"cell_type":"code","source":["#Importing libraries\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, Activation, MaxPool3D, TimeDistributed, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"],"metadata":{"id":"QmLJfzun9qfY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Building model\n","model = Sequential()\n","\n","#first layer of Conv3D with relu activation and MaxPool3D\n","model.add(Conv3D(128, 3, input_shape=(75, 46, 140, 1), padding=\"same\")) #input_shape equals dimensions of our data\n","model.add(Activation(\"relu\"))\n","model.add(MaxPool3D((1, 2, 2)))\n","\n","#second layer of Conv3D with relu activation and MaxPool3D\n","model.add(Conv3D(256, 3, padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPool3D((1, 2, 2)))\n","\n","#third layer of Conv3D with relu activation and MaxPool3D\n","model.add(Conv3D(75, 3, padding=\"same\"))\n","model.add(Activation(\"relu\"))\n","model.add(MaxPool3D((1, 2, 2)))\n","\n","#adding time distributed flatten layer that enables us to pass 75 inputs into the lstm that will output 75 units representing textbased characters\n","model.add(TimeDistributed(Flatten()))\n","\n","#adding 2 layers of LSTM\n","model.add(Bidirectional(LSTM(128,   kernel_initializer=\"Orthogonal\", return_sequences=True)))\n","model.add(Dropout(.5))  #randomly sets 50% of input units to 0 for each iteration --> prevents overfitting\n","\n","model.add(Bidirectional(LSTM(128,   kernel_initializer=\"Orthogonal\", return_sequences=True)))\n","model.add(Dropout(.5))  #randomly sets 50% of input units to 0 for each iteration --> prevents overfitting\n","\n","#adding dense layer\n","model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer=\"he_normal\", activation=\"softmax\"))"],"metadata":{"id":"arvMonhi-kv_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#have a look at the shape of the model\n","model.summary()"],"metadata":{"id":"FQX8YuoWEVVP","colab":{"base_uri":"https://localhost:8080/","height":609},"executionInfo":{"status":"ok","timestamp":1739270005059,"user_tz":-60,"elapsed":617,"user":{"displayName":"Ikbel","userId":"00064430573660104859"}},"outputId":"b3f562a5-b029-4d44-daa8-b16b76d89982"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m3,584\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d (\u001b[38;5;33mMaxPooling3D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m884,992\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d_1 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv3d_2 (\u001b[38;5;33mConv3D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m75\u001b[0m)      │         \u001b[38;5;34m518,475\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m75\u001b[0m)      │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d_2 (\u001b[38;5;33mMaxPooling3D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m75\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m6375\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m6,660,096\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m394,240\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m41\u001b[0m)              │          \u001b[38;5;34m10,537\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">518,475</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling3d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling3D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6375</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,660,096</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,537</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,471,924\u001b[0m (32.32 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,471,924</span> (32.32 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,471,924\u001b[0m (32.32 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,471,924</span> (32.32 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["**5. Training**"],"metadata":{"id":"AT4Y8w0RJNW0"}},{"cell_type":"code","source":["#Scheduler\n","def scheduler(epoch, lr):\n","  if epoch < 30:\n","    return lr\n","  else:\n","    return lr * tf.math.exp(-0.1)"],"metadata":{"id":"AFfQhXGJJTsV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["CTCLoss function is suited for learning tasks where the exact timing of data is not known and may vary (e.g. sound or video) thus why it needs the length of input and labels as well as y_true and y_pred in order to calculate the loss"],"metadata":{"id":"XIYXlTZRM562"}},{"cell_type":"code","source":["# CTC loss function\n","def CTCLoss(y_true, y_pred):\n","  batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","  input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","  label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","  input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","  label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","  loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n","  return loss"],"metadata":{"id":"E7SocyFdKCY0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code snippet defines a custom callback class named ProduceExample for TensorFlow (TF) models, specifically designed to work with Keras. Callbacks in Keras are functions that are called at certain points during model training, allowing you to hook into the training process for purposes such as logging, model checkpointing, or performing custom operations. The ProduceExample class is intended to be used during the training of a model, particularly for tasks involving sequence prediction, such as text generation or speech recognition."],"metadata":{"id":"dUQKm16WgXai"}},{"cell_type":"code","source":["class ProduceExample(tf.keras.callbacks.Callback):\n","  def __init__(self, dataset) -> None:\n","    self.dataset = dataset.as_numpy_iterator()\n","\n","  def on_epoch_end(self, epoch, logs=None) -> None:\n","    data = self.dataset.next()\n","    yhat = self.model.predict(data[0])\n","    decoded = tf.keras.backend.ctc_decode(yhat, [75], greedy=False)[0][0].numpy()\n","\n","    for x in range(len(yhat)):\n","      print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n","      print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n","      print('~' * 100)"],"metadata":{"id":"k4a_uRlobx7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Initiating legacy optimizer in order to be able to load the 95 epochs weights\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=CTCLoss)"],"metadata":{"id":"a7qLdbbxlogS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Compiling the model with optimizer Adam, learning rate and CTCLoss\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"],"metadata":{"id":"X8Ja7pO7hzII"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Downloading the checkpoints\n","url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n","output = 'checkpoints.zip'\n","gdown.download(url, output, quiet=False)\n","gdown.extractall('checkpoints.zip')"],"metadata":{"id":"eFheKkkPfY9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","#specify the full path with the desired filename and extension\n","checkpoint_filepath = './checkpoints'"],"metadata":{"id":"R50g7dJEoQ3R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create the ModelCheckpoint callback --> store training checkpoints for later use\n","checkpoint_callback = ModelCheckpoint(checkpoint_filepath, monitor='loss', save_weights_only=True)"],"metadata":{"id":"AjEN6Xxa2WPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ensuring learning rate drops each epoch\n","schedule_callback = LearningRateScheduler(scheduler)"],"metadata":{"id":"4kvRm1D8ir-Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Example callback calls the ProduceExample class to determine how well the model is performing after each epoch\n","example_callback = ProduceExample(data)"],"metadata":{"id":"QHJofPAcjB1b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loading weights for past training iterations. In case preexisting weights exist or have been produced from previous trainingsessions, they can be loaded into the model at this point and training can resume in order to increase performance."],"metadata":{"id":"SfFoDxlSwUnc"}},{"cell_type":"code","source":["model.load_weights(checkpoint_filepath)"],"metadata":{"id":"CET3Imyw5ZZA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Fitting the model\n","model.fit(train, validation_data=test, epochs=30, callbacks=[checkpoint_callback, schedule_callback])"],"metadata":{"id":"F0XAVH3Ajewj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6. Making prediction**"],"metadata":{"id":"og11IQtaRE0B"}},{"cell_type":"code","source":["#Compiling the model with optimizer Adam, learning rate and CTCLoss:\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=CTCLoss)"],"metadata":{"id":"AXk8ZNzqDL2o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Loading the weights\n","model.load_weights(checkpoint_filepath)"],"metadata":{"id":"3S3pXpjdYF-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = test.as_numpy_iterator()"],"metadata":{"id":"-2f1E0fYSq69"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample = test_data.next()"],"metadata":{"id":"fpiKzFTASwhA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yhat = model.predict(sample[0])"],"metadata":{"id":"oqtxoUFCS2GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"],"metadata":{"id":"J3jF1U-cU-qY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('~'*100, 'PREDICTIONS')\n","[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"],"metadata":{"id":"p9qwRvqbVBTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('~'*100, 'REAL TEXT')\n","[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"],"metadata":{"id":"7cs7653QVK4T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testing on video: A single datapoint from the dataset is selected in order to test the models prediction capabilities"],"metadata":{"id":"WsoTvKD-Q7eT"}},{"cell_type":"code","source":["sample = load_data(tf.convert_to_tensor('./data/videos/S_Banana_Later_Right_Hate.mp4'))"],"metadata":{"id":"JuqkLfXBP79w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 0:videos, 0: 1st video out of the batch,  0: return the first frame in the video\n","plt.imshow(sample[0][40])"],"metadata":{"id":"nXEMYK6VRhA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('~'*100, 'REAL TEXT')\n","[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"],"metadata":{"id":"NMJPV6bMQCOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yhat = model.predict(tf.expand_dims(sample[0], axis=0))"],"metadata":{"id":"QZ8cZyoyQIu0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"],"metadata":{"id":"Xh4DAHODRxyS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('~'*100, 'PREDICTIONS')\n","[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"],"metadata":{"id":"Ze5AkeN0SIR9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**7. Measuring performance of the model**"],"metadata":{"id":"z7DjWykAJ667"}},{"cell_type":"markdown","source":["Measuring word error rate (WER) and character error rate (CER) in order to assess the performance of the model"],"metadata":{"id":"5Vk0N0GcR4Wp"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.ops import string_ops\n","\n","# Word Error Rate\n","def wer(real_text, pred_text):\n","    real_words = real_text.split()\n","    pred_words = pred_text.split()\n","    real_words = [word for word in real_words if word!= \"\"]  # Remove empty strings\n","    pred_words = [word for word in pred_words if word!= \"\"]  # Remove empty strings\n","\n","    # Calculate the number of substitutions, insertions, and deletions\n","    substitutions = sum([real_word!= pred_word for real_word, pred_word in zip(real_words, pred_words)])\n","    insertions = len(pred_words) - len(real_words)\n","    deletions = len(real_words) - len(pred_words)\n","\n","    # Calculate the total number of operations\n","    total_operations = substitutions + insertions + deletions\n","\n","    # Calculate the word error rate\n","    wer = total_operations / len(real_words)\n","    return wer"],"metadata":{"id":"BGlWLCHzK3t2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cer(real_text, pred_text):\n","    real_chars = real_text.replace(\" \", \"\")  # Remove spaces to treat as individual characters\n","    pred_chars = pred_text.replace(\" \", \"\")  # Remove spaces to treat as individual characters\n","\n","    # Calculate the number of substitutions, insertions, and deletions\n","    substitutions = sum([real_char!= pred_char for real_char, pred_char in zip(real_chars, pred_chars)])\n","    insertions = len(pred_chars) - len(real_chars)\n","    deletions = len(real_chars) - len(pred_chars)\n","\n","    # Calculate the total number of operations\n","    total_operations = substitutions + insertions + deletions\n","\n","    # Calculate the character error rate\n","    cer = total_operations / len(real_chars)\n","    return cer"],"metadata":{"id":"AhEauCgKK6sQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculating the average WER and CER over every datapoint in the test set"],"metadata":{"id":"BXpMvBYLR-xN"}},{"cell_type":"code","source":["import numpy as np\n","\n","def get_average_wer_and_cer(test):\n","\n","  # Initialize variables to store the total WER, the total CER and the count of samples\n","  total_wer = 0\n","  total_cer = 0\n","  count = 0\n","\n","  # Iterate over each sample in the test dataset\n","  for sample in test:\n","      # Predict the text for the current sample\n","      yhat = model.predict(sample[0])\n","      decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()\n","      pred_text = tf.strings.reduce_join(num_to_char(decoded)).numpy().decode('utf-8')\n","\n","      # Get the actual text for the current sample\n","      real_text = tf.strings.reduce_join(num_to_char(sample[1])).numpy().decode('utf-8')\n","\n","      # Now pass the joined strings to the wer function\n","      wer_value = wer(real_text, pred_text)\n","      cer_value = cer(real_text, pred_text)\n","      # Update the total WER, the total CER and count\n","      total_wer += wer_value\n","      total_cer += cer_value\n","      count += 1\n","  # Calculate the average WER across all samples\n","  average_wer = total_wer / count if count > 0 else 0\n","  # Calculate the average CER across all samples\n","  average_cer = total_cer / count if count > 0 else 0\n","  print(f\"Average Word Error Rate: {average_wer}\")\n","  print(f\"Average Character Error Rate: {average_cer}\")"],"metadata":{"id":"cbfTLXDTvXk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["get_average_wer_and_cer(test_data)"],"metadata":{"id":"7ZeL-Fxuxpml"},"execution_count":null,"outputs":[]}]}